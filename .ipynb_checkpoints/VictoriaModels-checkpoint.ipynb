{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Skip to content\n",
    "Search or jump to…\n",
    "\n",
    "Pull requests\n",
    "Issues\n",
    "Marketplace\n",
    "Explore\n",
    " \n",
    "@ludmilagd \n",
    "Learn Git and GitHub without any code!\n",
    "Using the Hello World guide, you’ll start a branch, write comments, and open a pull request.\n",
    "\n",
    "\n",
    "lizziestenhaug\n",
    "/\n",
    "Stock-Market-Prediction\n",
    "1\n",
    "00\n",
    "Code\n",
    "Issues\n",
    "Pull requests\n",
    "Actions\n",
    "Projects\n",
    "Wiki\n",
    "Security\n",
    "Insights\n",
    "Stock-Market-Prediction/time-series.py\n",
    "@Vjeshurun\n",
    "Vjeshurun Add files via upload\n",
    "Latest commit 0cf90ea 13 minutes ago\n",
    " History\n",
    " 1 contributor\n",
    "364 lines (286 sloc)  10.8 KB\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fbprophet import Prophet\n",
    "import plotly\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_files_dict(pth='./data/'):\n",
    "    '''\n",
    "    create dictionary of files\n",
    "    '''\n",
    "    # pull all data files\n",
    "    files = os.listdir(pth)\n",
    "    print(files)\n",
    "\n",
    "    all_data = dict()\n",
    "    for file in files:\n",
    "\n",
    "        # create key and file path\n",
    "        file_key = file.split('_')[0]\n",
    "        file_path = os.path.join(pth, file)\n",
    "\n",
    "        # read the data\n",
    "        data = pd.read_csv(\n",
    "            file_path,\n",
    "            index_col='Date',\n",
    "            parse_dates=['Date']\n",
    "        )\n",
    "\n",
    "        # store data in dictionary\n",
    "        all_data[file_key] = data\n",
    "\n",
    "    return all_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_data(data, stock_name, pth='./figures/'):\n",
    "    '''\n",
    "    plot the data\n",
    "    '''\n",
    "    # create train and test\n",
    "    data[\"High\"][:'2016'].plot(figsize=(16, 4), legend=True)\n",
    "    data[\"High\"]['2017':].plot(figsize=(16, 4), legend=True)\n",
    "\n",
    "    # plot the data\n",
    "    plt.legend(['Training set (Before 2017)', 'Test set (2017 and beyond)'])\n",
    "    plt.title('{} stock price'.format(stock_name))\n",
    "    fig_path = os.path.join(pth, stock_name + '_train_test')\n",
    "\n",
    "    # save the data, pause, and close\n",
    "    plt.savefig(fig_path)\n",
    "    plt.pause(1)\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dl_train_test_split(all_data):\n",
    "    '''\n",
    "    create training/testing data and scaler object\n",
    "    '''\n",
    "    # create training and test set\n",
    "    training_set = all_data[:'2016'].iloc[:, 1:2].values\n",
    "    test_set = all_data['2017':].iloc[:, 1:2].values\n",
    "\n",
    "    # scale the data\n",
    "    sc = MinMaxScaler(feature_range=(0, 1))\n",
    "    training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "    # create training and test data\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60, 2768):\n",
    "        X_train.append(training_set_scaled[i - 60:i, 0])\n",
    "        y_train.append(training_set_scaled[i, 0])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # Reshaping X_train for efficient modelling\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    total_data = pd.concat(\n",
    "        (all_data[\"High\"][:'2016'], all_data[\"High\"]['2017':]), axis=0)\n",
    "    inputs = total_data[len(total_data) - len(test_set) - 60:].values\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "    inputs = sc.transform(inputs)\n",
    "\n",
    "    # Preparing X_testpython time\n",
    "    X_test = []\n",
    "    for i in range(60, 311):\n",
    "        X_test.append(inputs[i - 60:i, 0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_single_layer_small_rnn_model(X_train, y_train, X_test, sc):\n",
    "    '''\n",
    "    create single layer rnn model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # create a model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(6))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "    # fit the RNN model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=150)\n",
    "\n",
    "    # Finalizing predictions\n",
    "    scaled_preds = model.predict(X_test)\n",
    "    test_preds = sc.inverse_transform(scaled_preds)\n",
    "\n",
    "    return model, test_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_single_layer_rnn_model(X_train, y_train, X_test, sc):\n",
    "    '''\n",
    "    create single layer rnn model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # create a model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "    # fit the RNN model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=150)\n",
    "\n",
    "    # Finalizing predictions\n",
    "    scaled_preds = model.predict(X_test)\n",
    "    test_preds = sc.inverse_transform(scaled_preds)\n",
    "\n",
    "    return model, test_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(X_train, y_train, X_test, sc):\n",
    "    '''\n",
    "    create rnn model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # create a model\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "\n",
    "    # fit the RNN model\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=150)\n",
    "\n",
    "    # Finalizing predictions\n",
    "    scaled_preds = model.predict(X_test)\n",
    "    test_preds = sc.inverse_transform(scaled_preds)\n",
    "\n",
    "    return model, test_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_model(X_train, y_train, X_test, sc):\n",
    "    '''\n",
    "    create GRU model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # The GRU architecture\n",
    "    regressorGRU = Sequential()\n",
    "    # First GRU layer with Dropout regularisation\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True,\n",
    "                         input_shape=(X_train.shape[1], 1), activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))\n",
    "    regressorGRU.add(GRU(units=50, activation='tanh'))\n",
    "    regressorGRU.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    regressorGRU.compile(\n",
    "        optimizer=SGD(\n",
    "            lr=0.01,\n",
    "            decay=1e-7,\n",
    "            momentum=0.9,\n",
    "            nesterov=False),\n",
    "        loss='mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    regressorGRU.fit(X_train, y_train, epochs=50, batch_size=150)\n",
    "\n",
    "    GRU_predicted_stock_price = regressorGRU.predict(X_test)\n",
    "    GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)\n",
    "\n",
    "    return regressorGRU, GRU_predicted_stock_price\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_GRU_with_drop_out_model(X_train, y_train, X_test, sc):\n",
    "    '''\n",
    "    create GRU model trained on X_train and y_train\n",
    "    and make predictions on the X_test data\n",
    "    '''\n",
    "    # The GRU architecture\n",
    "    regressorGRU = Sequential()\n",
    "    # First GRU layer with Dropout regularisation\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True,\n",
    "                         input_shape=(X_train.shape[1], 1), activation='tanh'))\n",
    "    regressorGRU.add(Dropout(0.2))\n",
    "    # Second GRU layer\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))\n",
    "    regressorGRU.add(Dropout(0.2))\n",
    "    # Third GRU layer\n",
    "    regressorGRU.add(GRU(units=50, return_sequences=True, activation='tanh'))\n",
    "    regressorGRU.add(Dropout(0.2))\n",
    "    # Fourth GRU layer\n",
    "    regressorGRU.add(GRU(units=50, activation='tanh'))\n",
    "    regressorGRU.add(Dropout(0.2))\n",
    "    # The output layer\n",
    "    regressorGRU.add(Dense(units=1))\n",
    "    # Compiling the RNN\n",
    "    regressorGRU.compile(\n",
    "        optimizer=SGD(\n",
    "            lr=0.01,\n",
    "            decay=1e-7,\n",
    "            momentum=0.9,\n",
    "            nesterov=False),\n",
    "        loss='mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    regressorGRU.fit(X_train, y_train, epochs=50, batch_size=150)\n",
    "\n",
    "    GRU_predicted_stock_price = regressorGRU.predict(X_test)\n",
    "    GRU_predicted_stock_price = sc.inverse_transform(GRU_predicted_stock_price)\n",
    "\n",
    "    return regressorGRU, GRU_predicted_stock_price\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prophet_results(all_data,\n",
    "                           final_train_idx=2768,\n",
    "                           pred_periods=250):\n",
    "    '''\n",
    "    create prophet model trained on first 2768 rows by\n",
    "    default and predicts on last 250 rows\n",
    "    '''\n",
    "    # Pull train data\n",
    "    train_data = all_data[:final_train_idx].reset_index()[['Date', 'High']]\n",
    "    train_data.columns = ['ds', 'y']\n",
    "\n",
    "    # Create and fit model\n",
    "    prophet_model = Prophet()\n",
    "    prophet_model.fit(train_data)\n",
    "\n",
    "    # Provide predictions\n",
    "    test_dates = prophet_model.make_future_dataframe(periods=pred_periods)\n",
    "    forecast_prices = prophet_model.predict(test_dates)\n",
    "\n",
    "    return forecast_prices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prophet_daily_results(data):\n",
    "    '''\n",
    "    '''\n",
    "    test_results = pd.DataFrame()\n",
    "    for val in range(2768, 3019):\n",
    "\n",
    "        # format training dataframe\n",
    "        df = data['High'][:val].reset_index()\n",
    "        df.columns = ['ds', 'y']\n",
    "\n",
    "        # Instantiate and fit the model\n",
    "        proph_model = Prophet(daily_seasonality=True)\n",
    "        proph_model.fit(df)\n",
    "\n",
    "        # create test dataframe\n",
    "        test_dates = proph_model.make_future_dataframe(periods=1)\n",
    "\n",
    "        # store test results in dataframe\n",
    "        preds = proph_model.predict(test_dates).tail(1)\n",
    "        test_results = test_results.append(preds)\n",
    "\n",
    "    return test_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(actuals,\n",
    "                 stock_name,\n",
    "                 small_one_layer_preds,\n",
    "                 one_layer_preds,\n",
    "                 yearly_prophet_preds,\n",
    "                 gru_drop_preds,\n",
    "                 rnn_preds,\n",
    "                 gru_preds,\n",
    "                 plot_pth='./figures'):\n",
    "    '''\n",
    "    plot the results\n",
    "    '''\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(yearly_prophet_preds.reset_index()[\n",
    "             'yhat'].values[-250:], label='prophet yearly predictions')\n",
    "    plt.plot(stock_data[\"High\"]['2017':].values[:-1], label='actual values')\n",
    "    plt.plot(small_one_layer_preds, label='Single Layer Small RNN values')\n",
    "    plt.plot(one_layer_preds, label='Single Layer RNN values')\n",
    "    plt.plot(gru_drop_preds, label='GRU with dropout values')\n",
    "    plt.plot(rnn_preds, label='RNN values')\n",
    "    plt.plot(gru_preds, label='GRU values')\n",
    "    plt.title('{} Predictions from Prophet vs. Actual'.format(stock_name))\n",
    "    plt.legend()\n",
    "\n",
    "    fig_path = os.path.join(plot_pth, 'results', stock_name + '_preds')\n",
    "\n",
    "    # save the data, pause, and close\n",
    "    plt.savefig(fig_path)\n",
    "    plt.pause(1)\n",
    "    plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    all_data = create_files_dict()\n",
    "    for stock_name, stock_data in all_data.items():\n",
    "        # initial plots\n",
    "        plot_data(stock_data, stock_name)\n",
    "\n",
    "        # create dl data\n",
    "        X_train, y_train, X_test, sc = create_dl_train_test_split(stock_data)\n",
    "\n",
    "        # create small single layer small rnn preds\n",
    "        small_single_layer_rnn, small_one_layer_preds = create_single_layer_small_rnn_model(\n",
    "            X_train, y_train, X_test, sc)\n",
    "\n",
    "        # create single layer rnn preds\n",
    "        single_layer_rnn, one_layer_preds = create_single_layer_rnn_model(\n",
    "            X_train, y_train, X_test, sc)\n",
    "\n",
    "        # rnn daily preds\n",
    "        rnn_model, rnn_preds = create_rnn_model(X_train, y_train, X_test, sc)\n",
    "\n",
    "        # gru daily preds\n",
    "        gru_model, gru_preds = create_GRU_model(X_train, y_train, X_test, sc)\n",
    "\n",
    "        # gru daily preds\n",
    "        gru_drop_model, gru_drop_preds = create_GRU_with_drop_out_model(\n",
    "            X_train, y_train, X_test, sc)\n",
    "\n",
    "        # yearly preds\n",
    "        yearly_preds = create_prophet_results(stock_data)\n",
    "\n",
    "        # daily preds\n",
    "        # prophet_daily_preds = create_prophet_daily_results(stock_data)\n",
    "\n",
    "        # plot results\n",
    "        plot_results(stock_data,\n",
    "                     stock_name,\n",
    "                     small_one_layer_preds,\n",
    "                     one_layer_preds,\n",
    "                     yearly_preds,\n",
    "                     gru_drop_preds,\n",
    "                     rnn_preds,\n",
    "                     gru_preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
